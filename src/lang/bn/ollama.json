{
  "OLLAMA_DEBUG": "অতিরিক্ত ডিবাগ তথ্য দেখান (যেমন OLLAMA_DEBUG=1)",
  "OLLAMA_HOST": "ollama সার্ভারের জন্য IP ঠিকানা (ডিফল্ট 127.0.0.1:11434)",
  "OLLAMA_KEEP_ALIVE": "মডেল মেমরিতে লোড থাকার সময়কাল (ডিফল্ট \"5m\")",
  "OLLAMA_MAX_LOADED_MODELS": "প্রতি GPU তে সর্বাধিক লোড করা মডেলের সংখ্যা",
  "OLLAMA_MAX_QUEUE": "সর্বাধিক সারিবদ্ধ অনুরোধের সংখ্যা",
  "OLLAMA_MODELS": "মডেল ডিরেক্টরির পাথ",
  "OLLAMA_NUM_PARALLEL": "সর্বাধিক সমান্তরাল অনুরোধের সংখ্যা",
  "OLLAMA_NOPRUNE": "স্টার্টআপে মডেল ব্লব প্রুন করবেন না",
  "OLLAMA_ORIGINS": "অনুমোদিত উৎসের একটি কমা বিভক্ত তালিকা",
  "OLLAMA_SCHED_SPREAD": "সর্বদা সব GPU জুড়ে মডেল শিডিউল করুন",
  "OLLAMA_FLASH_ATTENTION": "ফ্ল্যাশ অ্যাটেনশন সক্রিয় করা হয়েছে",
  "OLLAMA_KV_CACHE_TYPE": "K/V ক্যাশের জন্য কোয়ান্টাইজেশন টাইপ (ডিফল্ট: f16)",
  "OLLAMA_LLM_LIBRARY": "অটোডিটেকশন বাইপাস করতে LLM লাইব্রেরি সেট করুন",
  "OLLAMA_GPU_OVERHEAD": "প্রতি GPU তে VRAM এর একটি অংশ রিজার্ভ করুন (বাইট)",
  "OLLAMA_LOAD_TIMEOUT": "হাল ছেড়ে দেওয়ার আগে মডেল লোড স্টল করার জন্য কতক্ষণ অনুমতি দেবেন (ডিফল্ট \"5m\")",
  "needServiceRun": "অনুগ্রহ করে প্রথমে Olama সার্ভিস শুরু করুন",
  "size": "সাইজ",
  "model": "মডেল"
}
