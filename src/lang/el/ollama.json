{
  "OLLAMA_DEBUG": "Εμφάνιση πρόσθετων πληροφοριών αποσφαλμάτωσης (π.χ. OLLAMA_DEBUG=1)",
  "OLLAMA_HOST": "Διεύθυνση IP για τον εξυπηρετητή ollama (προεπιλογή 127.0.0.1:11434)",
  "OLLAMA_KEEP_ALIVE": "Η διάρκεια που τα μοντέλα παραμένουν φορτωμένα στη μνήμη (προεπιλογή \"5m\")",
  "OLLAMA_MAX_LOADED_MODELS": "Μέγιστος αριθμός φορτωμένων μοντέλων ανά GPU",
  "OLLAMA_MAX_QUEUE": "Μέγιστος αριθμός αιτήσεων στην ουρά",
  "OLLAMA_MODELS": "Η διαδρομή προς τον κατάλογο μοντέλων",
  "OLLAMA_NUM_PARALLEL": "Μέγιστος αριθμός παράλληλων αιτήσεων",
  "OLLAMA_NOPRUNE": "Μην κλαδεύετε το μοντέλο κατά την εκκίνηση",
  "OLLAMA_ORIGINS": "Μια λίστα επιτρεπόμενης προέλευσης διαχωρισμένη με κόμμα",
  "OLLAMA_SCHED_SPREAD": "Πάντα προγραμματισμό μοντέλου σε όλες τις GPU",
  "OLLAMA_FLASH_ATTENTION": "Προσοχή ενεργού φλας",
  "OLLAMA_KV_CACHE_TYPE": "Τύπος ποσοτικού προσδιορισμού για τη μνήμη cache K/V (προεπιλογή: f16)",
  "OLLAMA_LLM_LIBRARY": "Ορισμός βιβλιοθήκης LLM για παράκαμψη αυτόματης ανίχνευσης",
  "OLLAMA_GPU_OVERHEAD": "Κρατήστε ένα μέρος VRAM ανά GPU (bytes)",
  "OLLAMA_LOAD_TIMEOUT": "Πόσο καιρό να επιτρέψει τα φορτία μοντέλου να σταματήσουν πριν εγκαταλείψουν (προεπιλογή \"5m\")",
  "needServiceRun": "Παρακαλώ ξεκινήστε πρώτα την υπηρεσία Olama",
  "size": "Μέγεθος",
  "model": "Μοντέλα"
}
